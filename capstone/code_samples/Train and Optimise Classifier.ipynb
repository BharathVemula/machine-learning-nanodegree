{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "\n",
      "Training and optimisation report with 10 principal component\n",
      "\n",
      "Grid Search\n",
      "0.928986838078\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Training and optimisation report with 25 principal component\n",
      "\n",
      "Grid Search\n",
      "0.977043158861\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Training and optimisation report with 50 principal component\n",
      "\n",
      "Grid Search\n",
      "0.978369554127\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Training and optimisation report with 100 principal component\n",
      "\n",
      "Grid Search\n",
      "0.976635037241\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Training and optimisation report with 784 principal component\n",
      "\n",
      "Grid Search\n",
      "0.972655851444\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%capture cap --no-stderr\n",
    "\n",
    "# with open('train.txt', 'w') as f:\n",
    "#     f.write(cap.stdout)\n",
    "\n",
    "# del cap \n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "components = [ 25, 50, 100 ]\n",
    "y = pickle.load(open('target.pkl', 'r'))\n",
    "\n",
    "def all_same(items):\n",
    "  return len(set(items)) == 1\n",
    "\n",
    "for c in components:\n",
    "    \n",
    "    print '-------------------------------------------------------'\n",
    "    print\n",
    "    print 'Training and optimisation report with {0} principal component'.format(c)\n",
    "    print\n",
    "    filename = 'data-{0}-components.pkl'.format(c)\n",
    "    X = pickle.load(open(filename, 'r'))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.14, random_state=0)\n",
    "    \n",
    "    \n",
    "#     # Save split test train datasets with pickle    \n",
    "#     X_train_file = 'X_train-for-{0}-components.pkl'.format(c)\n",
    "#     file = open(X_train_file, 'w')\n",
    "#     pickle.dump(X_train, file)\n",
    "#     file.close()\n",
    "\n",
    "#     X_test_file = 'X_test-for-{0}-components.pkl'.format(c)\n",
    "#     file = open(X_test_file, 'w')\n",
    "#     pickle.dump(X_test, file)\n",
    "#     file.close()\n",
    "\n",
    "#     y_train_file = 'y_train-for-{0}-components.pkl'.format(c)\n",
    "#     file = open(y_train_file, 'w')\n",
    "#     pickle.dump(y_train, file)\n",
    "#     file.close()\n",
    "\n",
    "#     y_test_file = 'y_test-for-{0}-components.pkl'.format(c)\n",
    "#     file = open(y_test_file, 'w')\n",
    "#     pickle.dump(y_test, file)\n",
    "#     file.close()\n",
    "\n",
    "    y_pred = np.empty(len(y_test), dtype=np.int)\n",
    "    \n",
    "    knn_tuned_parameters = []\n",
    "    \n",
    "    svm_tuned_parameters = [\n",
    "                        {\n",
    "                        'kernel': ['rbf'],\n",
    "                        'gamma': [1e-3, 1e-4],\n",
    "                        'C': [1, 10, 100, 1000]\n",
    "                        },\n",
    "                        {\n",
    "                        'kernel': ['poly'],\n",
    "                        'gamma': [1e-3, 1e-4],\n",
    "                        'C': [1, 10, 100, 1000],\n",
    "                        'degree': [5, 6, 7]\n",
    "                        }\n",
    "                        ]\n",
    "\n",
    "    print 'Grid Search'\n",
    "#     clf = GridSearchCV(RandomForestClassifier(), tuned_parameters, cv=5, scoring='accuracy', verbose=1)\n",
    "#     clf.fit(X_train, y_train)\n",
    "    \n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=3, p=2)\n",
    "    knn_clf.fit(X_train, y_train)\n",
    "    \n",
    "#     clf_file = 'model-for-{0}-components.pkl'.format(c)\n",
    "#     file = open(clf_file, 'w')\n",
    "#     pickle.dump(clf, file)\n",
    "#     file.close()\n",
    "\n",
    "    kneighbors = knn_clf.kneighbors(X_test, return_distance=False)\n",
    "\n",
    "    for idx, indices in enumerate(kneighbors):\n",
    "      neighbors = [X_train[i] for i in indices]\n",
    "      neighbors_labels = [y_train[i] for i in indices]\n",
    "      \n",
    "      if all_same(neighbors_labels):\n",
    "        y_pred[idx] = neighbors_labels[0]\n",
    "      else:\n",
    "        # else fit a SVM classifier using the neighbors, and label the test samples\n",
    "        svm_clf = svm.SVC(C=0.5, kernel='rbf', decision_function_shape='ovo', random_state=42)\n",
    "        svm_clf.fit(neighbors, neighbors_labels)\n",
    "        label = svm_clf.predict(X_test[idx].reshape(1, -1))\n",
    "        y_pred[idx] = label\n",
    "#     print 'Best parameters set found on development set:'\n",
    "#     print clf.best_params_\n",
    "#     print\n",
    "#     print 'Grid scores on development set:'\n",
    "#     means = clf.cv_results_['mean_test_score']\n",
    "#     stds = clf.cv_results_['std_test_score']\n",
    "#     for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "#         print '%0.3f (+/-%0.03f) for %r' % (mean, std * 2, params)\n",
    "#     y_true, y_pred = y_test, clf.predict(X_test)\n",
    "#     _confusion_matrix = confusion_matrix(y_true, y_pred)\n",
    "#     print(_confusion_matrix)\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "#     y_true = y_pred = None\n",
    "    print\n",
    "    print\n",
    "    print '-------------------------------------------------------'\n",
    "    print\n",
    "     \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
